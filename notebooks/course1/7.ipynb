{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models, datasets\n",
    "import imageio\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_dir = './flower_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'"
   ],
   "id": "e7b3bee18e2d7f6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(45), # Random rotation, choose one between -45 and 45\n",
    "        transforms.CenterCrop(224), # Crop from the center\n",
    "        transforms.RandomHorizontalFlip(p=0.5), # Random horizontal flip, select one probability\n",
    "        transforms.RandomVerticalFlip(p=0.5), # Random vertical flip\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.1, hue=0.1), # Arg 1 is brightness, arg 2 is contrast, arg 3 is saturation, arg 4 is hue\n",
    "        transforms.RandomGrayscale(p=0.025), # Convert the probability into gray rate, R=G=B for 3 channels\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Average, standard error\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ],
   "id": "6f0dd40e97280afe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 8\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(str(os.path.join(data_dir, x)), data_transforms[x]) for x in ['train', 'valid']}\n",
    "data_loaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True) for x in ['train', 'valid']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
    "class_names = image_datasets['train'].classes"
   ],
   "id": "3113ad7eb724dd4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "image_datasets",
   "id": "a489284d2302116",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_loaders",
   "id": "c362f51b0f1c1c0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset_sizes",
   "id": "dc4d688c73392939",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ],
   "id": "fc2070e5f69881b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cat_to_name",
   "id": "90027f0011360990",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def im_convert(tensor):\n",
    "    \"\"\"Display the data\"\"\"\n",
    "    \n",
    "    image = tensor.to('cpu').clone().detach()\n",
    "    image = image.numpy().squeeze()\n",
    "    image = image.transpose(1, 2, 0)\n",
    "    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
    "    image = image.clip(0, 1)\n",
    "    \n",
    "    return image"
   ],
   "id": "af0ba8428c63c7f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = plt.figure(figsize=(20, 12))\n",
    "columns = 4\n",
    "rows = 2\n",
    "\n",
    "data_iter = iter(data_loaders['valid'])\n",
    "inputs, classes = next(data_iter)\n",
    "\n",
    "for idx in range(columns * rows):\n",
    "    ax = fig.add_subplot(rows, columns, idx + 1, xticks=[], yticks=[])\n",
    "    ax.set_title(cat_to_name[str(int(class_names[classes[idx]]))])\n",
    "    plt.imshow(im_convert(inputs[idx]))\n",
    "plt.show()"
   ],
   "id": "471c7735589985ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_name = 'resnet' # Choices are vast ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet', 'inception']\n",
    "# Whether to use pre-trained features by others\n",
    "feature_extract = True"
   ],
   "id": "63f258298ab5170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Whether to use GPU to train\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if train_on_gpu:\n",
    "    print('CUDA is available! Training on GPU...')\n",
    "else:\n",
    "    print('CUDA is not available. Training on CPU...')\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")"
   ],
   "id": "bf94b9b7d4a04dbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True"
   ],
   "id": "79aabcd37f8fda03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_ft = models.resnet152()\n",
    "model_ft"
   ],
   "id": "d7e735cdc87767a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Select a suitable model, different models have different initializing methods\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    \n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet 152\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 102),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        input_size = 224\n",
    "    \n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" AlexNet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg16(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1, 1),stride=(1, 1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxiliary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 299\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "        \n",
    "    return model_ft, input_size"
   ],
   "id": "e181afd85462b34b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_ft, input_size = initialize_model(model_name, 102, feature_extract, use_pretrained=True)\n",
    "\n",
    "# GPU calculation\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Model save\n",
    "filename = \"./data/checkpoint.pth\"\n",
    "\n",
    "# Whether to train all layers\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\", name)\n",
    "else:\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(\"\\t\", name)"
   ],
   "id": "6cd4e3bc54f1b492",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_ft",
   "id": "a95c67b22cc3b2ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Optimizer settings\n",
    "optimizer_ft = optim.Adam(params_to_update, lr=1e-2)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) # Learning rate will be decreased to 1/10 of the original one every 7 epochs\n",
    "# Since the last layer is LogSoftMax, nn.CrossEntropyLoss can't be used to calculate, nn.CrossEntropyLoss stands as a combination of LogSoftMax and nn.NLLLoss\n",
    "criterion = nn.NLLLoss()"
   ],
   "id": "d592177d0f54eac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False, filename=filename):\n",
    "    since = time.time()\n",
    "    best_acc = 0\n",
    "    model.to(device)\n",
    "    \n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    LRs = [optimizer.param_groups[0]['lr']]\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Train and validate\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train() # Train\n",
    "            else:\n",
    "                model.eval() # Validate\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Loop through the data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Set to zero\n",
    "                optimizer.zero_grad()\n",
    "                # Only calculate and update gradients during training\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4 * loss2\n",
    "                    else: # resnet will execute here\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    # Update weights during training\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                # Calculate losses\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            time_elapsed = time.time() - since\n",
    "            print('Time elapsed {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # Obtain the model at the best epoch\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                state = {\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                }\n",
    "                torch.save(state, filename)\n",
    "            if phase == 'valid':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                valid_losses.append(epoch_loss)\n",
    "                scheduler.step(epoch_loss)\n",
    "            if phase == 'train':\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                train_losses.append(epoch_loss)\n",
    "                \n",
    "        print('Optimizer learning rate: {:.7f}'.format(optimizer.param_groups[0]['lr']))\n",
    "        LRs.append(optimizer.param_groups[0]['lr'])\n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
    "    \n",
    "    # After training, mark the best one as the result of the model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, train_acc_history, valid_losses, train_losses, LRs"
   ],
   "id": "f5643c61f35d3753",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_ft, val_acc_history, train_acc_history, valid_losses, train_losses, LRs = train_model(model_ft, data_loaders, criterion, optimizer_ft, num_epochs=20, is_inception=(model_name==\"inception\"))",
   "id": "93abb06150b2781e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c4804b8ece42ffe8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
